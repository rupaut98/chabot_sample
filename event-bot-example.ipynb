{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install langchain-community faiss-cpu openai tiktoken langchain-openai","metadata":{"execution":{"iopub.status.busy":"2024-11-11T05:25:20.789206Z","iopub.execute_input":"2024-11-11T05:25:20.789610Z","iopub.status.idle":"2024-11-11T05:25:44.299490Z","shell.execute_reply.started":"2024-11-11T05:25:20.789563Z","shell.execute_reply":"2024-11-11T05:25:44.298121Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting langchain-community\n  Downloading langchain_community-0.3.5-py3-none-any.whl.metadata (2.9 kB)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\nCollecting openai\n  Downloading openai-1.54.3-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (0.8.0)\nCollecting langchain-openai\n  Downloading langchain_openai-0.2.6-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.0.30)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (3.9.5)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.6.7)\nCollecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nCollecting langchain<0.4.0,>=0.3.6 (from langchain-community)\n  Downloading langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\nCollecting langchain-core<0.4.0,>=0.3.15 (from langchain-community)\n  Downloading langchain_core-0.3.15-py3-none-any.whl.metadata (6.3 kB)\nCollecting langsmith<0.2.0,>=0.1.125 (from langchain-community)\n  Downloading langsmith-0.1.142-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (1.26.4)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (8.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from faiss-cpu) (21.3)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (4.4.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\nCollecting jiter<1,>=0.4.0 (from openai)\n  Downloading jiter-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (2.9.2)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.4)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.10/site-packages (from openai) (4.12.2)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2024.5.15)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nCollecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain<0.4.0,>=0.3.6->langchain-community)\n  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (1.33)\nCollecting packaging (from faiss-cpu)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.4)\nCollecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.125->langchain-community)\n  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\nRequirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (1.26.18)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community) (3.0.3)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-community) (2.4)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nDownloading langchain_community-0.3.5-py3-none-any.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading faiss_cpu-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading openai-1.54.3-py3-none-any.whl (389 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_openai-0.2.6-py3-none-any.whl (50 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading jiter-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (327 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.5/327.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain-0.3.7-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.15-py3-none-any.whl (408 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.7/408.7 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langsmith-0.1.142-py3-none-any.whl (306 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.7/306.7 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\nDownloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\nDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, jiter, httpx-sse, requests-toolbelt, faiss-cpu, pydantic-settings, openai, langsmith, langchain-core, langchain-text-splitters, langchain-openai, langchain, langchain-community\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: requests-toolbelt\n    Found existing installation: requests-toolbelt 0.10.1\n    Uninstalling requests-toolbelt-0.10.1:\n      Successfully uninstalled requests-toolbelt-0.10.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.2 which is incompatible.\njupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nthinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed faiss-cpu-1.9.0 httpx-sse-0.4.0 jiter-0.7.0 langchain-0.3.7 langchain-community-0.3.5 langchain-core-0.3.15 langchain-openai-0.2.6 langchain-text-splitters-0.3.2 langsmith-0.1.142 openai-1.54.3 packaging-24.2 pydantic-settings-2.6.1 requests-toolbelt-1.0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install git+https://github.com/openai/whisper.git\n!pip install ffmpeg-python","metadata":{"execution":{"iopub.status.busy":"2024-11-11T05:24:32.751520Z","iopub.execute_input":"2024-11-11T05:24:32.752536Z","iopub.status.idle":"2024-11-11T05:25:20.786815Z","shell.execute_reply.started":"2024-11-11T05:24:32.752478Z","shell.execute_reply":"2024-11-11T05:25:20.785463Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/openai/whisper.git\n  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-f66pzff4\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-f66pzff4\n  Resolved https://github.com/openai/whisper.git to commit 271445b2f24f00f8175c4fb7ae91876f7451dfc1\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20240930) (0.60.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20240930) (1.26.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20240930) (2.4.0+cpu)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20240930) (4.66.4)\nRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20240930) (10.3.0)\nCollecting tiktoken (from openai-whisper==20240930)\n  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nCollecting triton>=2.0.0 (from openai-whisper==20240930)\n  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton>=2.0.0->openai-whisper==20240930) (3.15.1)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->openai-whisper==20240930) (0.43.0)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken->openai-whisper==20240930) (2024.5.15)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (2024.6.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->openai-whisper==20240930) (2.1.5)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->openai-whisper==20240930) (1.3.0)\nDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: openai-whisper\n  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803557 sha256=5294eadd424e8cc217b2acafde828789f6ab0a509c9093bfe6f69fdeb1b1211e\n  Stored in directory: /tmp/pip-ephem-wheel-cache-9dy_v_n6/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\nSuccessfully built openai-whisper\nInstalling collected packages: triton, tiktoken, openai-whisper\nSuccessfully installed openai-whisper-20240930 tiktoken-0.8.0 triton-3.1.0\nCollecting ffmpeg-python\n  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from ffmpeg-python) (1.0.0)\nDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\nInstalling collected packages: ffmpeg-python\nSuccessfully installed ffmpeg-python-0.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from langchain.schema import Document\nfrom langchain.prompts import PromptTemplate\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain_openai import ChatOpenAI\nfrom langchain.chains import ConversationalRetrievalChain\nfrom langchain.vectorstores.faiss import FAISS\nfrom langchain.docstore.in_memory import InMemoryDocstore\nfrom langchain_openai import OpenAIEmbeddings\nimport faiss","metadata":{"execution":{"iopub.status.busy":"2024-11-11T05:25:44.301339Z","iopub.execute_input":"2024-11-11T05:25:44.301886Z","iopub.status.idle":"2024-11-11T05:25:46.410848Z","shell.execute_reply.started":"2024-11-11T05:25:44.301792Z","shell.execute_reply":"2024-11-11T05:25:46.409519Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"api_key=''","metadata":{"execution":{"iopub.status.busy":"2024-11-11T05:25:46.413346Z","iopub.execute_input":"2024-11-11T05:25:46.413870Z","iopub.status.idle":"2024-11-11T05:25:46.419810Z","shell.execute_reply.started":"2024-11-11T05:25:46.413830Z","shell.execute_reply":"2024-11-11T05:25:46.418686Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"user_data = {\n  \"user_1\": [\n    {\n      \"event_id\": \"1\",\n      \"subject\": \"Team Standup Meeting\",\n      \"start_time\": \"2024-11-10 11:00\",\n      \"description\": \"Daily team sync-up to discuss project progress and blockers.\"\n    },\n    {\n      \"event_id\": \"2\",\n      \"subject\": \"Client Presentation\",\n      \"start_time\": \"2024-11-11 13:00\",\n      \"description\": \"Present project deliverables to the client.\"\n    },\n    {\n      \"event_id\": \"3\",\n      \"subject\": \"Morning Yoga Session\",\n      \"start_time\": \"2024-11-11 09:00\",\n      \"description\": \"A relaxing start to the day with a 1-hour yoga session.\"\n    },\n    {\n      \"event_id\": \"4\",\n      \"subject\": \"Project Kickoff Meeting\",\n      \"start_time\": \"2024-11-12 11:00\",\n      \"description\": \"Initial meeting to align stakeholders on project goals and timelines.\"\n    },\n    {\n      \"event_id\": \"5\",\n      \"subject\": \"Lunch with Mentor\",\n      \"start_time\": \"2024-11-12 13:00\",\n      \"description\": \"Catch up and discuss career growth strategies over lunch.\"\n    },\n    {\n      \"event_id\": \"6\",\n      \"subject\": \"Code Review Session\",\n      \"start_time\": \"2024-11-13 09:00\",\n      \"description\": \"Review and provide feedback on recent pull requests.\"\n    },\n    {\n      \"event_id\": \"7\",\n      \"subject\": \"Quarterly Planning\",\n      \"start_time\": \"2024-11-13 11:00\",\n      \"description\": \"Plan the next quarter's objectives with the team.\"\n    },\n    {\n      \"event_id\": \"8\",\n      \"subject\": \"1:1 with Manager\",\n      \"start_time\": \"2024-11-14 13:00\",\n      \"description\": \"Discuss performance and goals in a one-on-one meeting.\"\n    },\n    {\n      \"event_id\": \"9\",\n      \"subject\": \"Technical Workshop\",\n      \"start_time\": \"2024-11-14 09:00\",\n      \"description\": \"Attend a workshop on advanced cloud architecture.\"\n    },\n    {\n      \"event_id\": \"10\",\n      \"subject\": \"Weekly Retrospective\",\n      \"start_time\": \"2024-11-15 11:00\",\n      \"description\": \"Reflect on the week's progress and identify areas for improvement.\"\n    },\n    {\n      \"event_id\": \"30\",\n      \"subject\": \"Hackathon Kickoff\",\n      \"start_time\": \"2024-11-25 09:00\",\n      \"description\": \"Start of the annual company hackathon.\"\n    }\n  ],\n  \"user_2\": [\n    {\n      \"event_id\": \"1\",\n      \"subject\": \"Marketing Strategy Meeting\",\n      \"start_time\": \"2024-11-10 11:00\",\n      \"description\": \"Discuss Q1 marketing strategies with the team.\"\n    },\n    {\n      \"event_id\": \"2\",\n      \"subject\": \"Product Launch Event\",\n      \"start_time\": \"2024-11-11 13:00\",\n      \"description\": \"Launch the new product line to the public.\"\n    },\n    {\n      \"event_id\": \"3\",\n      \"subject\": \"Morning Run\",\n      \"start_time\": \"2024-11-11 09:00\",\n      \"description\": \"Start the day with a refreshing 5K run.\"\n    },\n    {\n      \"event_id\": \"4\",\n      \"subject\": \"Budget Review Meeting\",\n      \"start_time\": \"2024-11-12 11:00\",\n      \"description\": \"Review the department's budget for the next quarter.\"\n    },\n    {\n      \"event_id\": \"5\",\n      \"subject\": \"Client Networking Lunch\",\n      \"start_time\": \"2024-11-12 13:00\",\n      \"description\": \"Build relationships with key clients over lunch.\"\n    },\n    {\n      \"event_id\": \"6\",\n      \"subject\": \"Content Planning Session\",\n      \"start_time\": \"2024-11-13 09:00\",\n      \"description\": \"Plan content for the upcoming social media campaign.\"\n    },\n    {\n      \"event_id\": \"7\",\n      \"subject\": \"Sales Team Training\",\n      \"start_time\": \"2024-11-13 11:00\",\n      \"description\": \"Training session for the sales team on new CRM software.\"\n    },\n    {\n      \"event_id\": \"8\",\n      \"subject\": \"Vendor Call\",\n      \"start_time\": \"2024-11-14 13:00\",\n      \"description\": \"Discuss contract terms with a new vendor.\"\n    },\n    {\n      \"event_id\": \"9\",\n      \"subject\": \"Leadership Workshop\",\n      \"start_time\": \"2024-11-14 09:00\",\n      \"description\": \"Participate in a workshop on leadership skills.\"\n    },\n    {\n      \"event_id\": \"10\",\n      \"subject\": \"Team Building Activity\",\n      \"start_time\": \"2024-11-15 11:00\",\n      \"description\": \"Engage in fun activities to strengthen team bonds.\"\n    },\n    {\n      \"event_id\": \"30\",\n      \"subject\": \"Year-End Review\",\n      \"start_time\": \"2024-11-25 09:00\",\n      \"description\": \"Comprehensive review of the year's performance and achievements.\"\n    }\n  ]\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T05:25:46.974761Z","iopub.execute_input":"2024-11-11T05:25:46.975167Z","iopub.status.idle":"2024-11-11T05:25:46.988957Z","shell.execute_reply.started":"2024-11-11T05:25:46.975128Z","shell.execute_reply":"2024-11-11T05:25:46.987566Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def setup_user_data(user_id, events):\n    documents = [\n        Document(page_content=f\"{event['subject']} on {event['start_time']} - {event['description']}\", metadata=event)\n        for event in events\n    ]\n\n    embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key=api_key)\n    embeddings = embedding_model.embed_documents([doc.page_content for doc in documents])\n    \n\n    dimension = len(embeddings[0])\n    index = faiss.IndexFlatL2(dimension)\n    docstore = InMemoryDocstore({str(i): doc for i, doc in enumerate(documents)})\n    index_to_docstore_id = {i: str(i) for i in range(len(documents))}\n    \n    faiss_index = FAISS(\n        index=index,\n        docstore=docstore,\n        index_to_docstore_id=index_to_docstore_id,\n        embedding_function=embedding_model.embed_query\n    )\n    faiss_index.add_texts([doc.page_content for doc in documents])\n    \n    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n    \n    return faiss_index, memory","metadata":{"execution":{"iopub.status.busy":"2024-11-11T05:25:53.016388Z","iopub.execute_input":"2024-11-11T05:25:53.017647Z","iopub.status.idle":"2024-11-11T05:25:53.028849Z","shell.execute_reply.started":"2024-11-11T05:25:53.017587Z","shell.execute_reply":"2024-11-11T05:25:53.027179Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"user_chains = {}\nfor user_id, events in user_data.items():\n    faiss_index, memory = setup_user_data(user_id, events)\n    retriever = faiss_index.as_retriever(search_kwargs={\"k\": 3})\n    prompt_template = PromptTemplate.from_template(template=\"\"\"\n        You are a helpful assistant providing information about events.\n\n        Context: {context}\n\n        Chat History: {chat_history}\n\n        Question: {question}\n\n        Answer:\n    \"\"\")\n    llm = ChatOpenAI(temperature=0.3, model=\"gpt-4o-mini\", openai_api_key=api_key)\n    \n    qa_chain = ConversationalRetrievalChain.from_llm(\n        llm=llm,\n        retriever=retriever,\n        memory=memory,\n        return_source_documents=False,\n        combine_docs_chain_kwargs={\"prompt\": prompt_template}\n    )\n    user_chains[user_id] = qa_chain","metadata":{"execution":{"iopub.status.busy":"2024-11-11T05:25:54.220184Z","iopub.execute_input":"2024-11-11T05:25:54.220768Z","iopub.status.idle":"2024-11-11T05:26:06.293414Z","shell.execute_reply.started":"2024-11-11T05:25:54.220708Z","shell.execute_reply":"2024-11-11T05:26:06.292169Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/3808713830.py:24: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef query_user(user_id, question):\n    qa_chain = user_chains[user_id]\n    response = qa_chain.invoke({\"question\": question, \"chat_history\": []})\n    return response[\"answer\"]\n\n# Test queries\nprint(\"User 1 Query:\")\nprint(query_user(\"user_1\", \"What events do I have this week?\"))\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T05:26:06.295249Z","iopub.execute_input":"2024-11-11T05:26:06.295640Z","iopub.status.idle":"2024-11-11T05:26:08.426134Z","shell.execute_reply.started":"2024-11-11T05:26:06.295602Z","shell.execute_reply":"2024-11-11T05:26:08.425007Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"User 1 Query:\nThis week, you have the following events scheduled:\n\n1. **Team Standup Meeting** on **2024-11-10 at 11:00** - A daily team sync-up to discuss project progress and blockers.\n   \n2. **Client Presentation** on **2024-11-11 at 13:00** - Present project deliverables to the client.\n\n3. **Weekly Retrospective** on **2024-11-15 at 11:00** - Reflect on the week's progress and identify areas for improvement.\n","output_type":"stream"}]},{"cell_type":"code","source":"import whisper\nimport tempfile\nimport os\nimport ffmpeg\nfrom IPython.display import Audio\n\ndef transcribe_audio_kaggle(audio_file_path, model_name=\"base\"):\n    model = whisper.load_model(model_name)\n    result = model.transcribe(audio_file_path)\n    return result['text'] \n\ndef query_user_with_audio(user_id, audio_file_path):\n    transcription = transcribe_audio_kaggle(audio_file_path)\n    print(f\"Transcribed Question: {transcription}\")\n    \n    answer = query_user(user_id, transcription)\n    return answer\n\naudio_path = '/kaggle/input/audioo/Rev.mp3'\nprint(query_user_with_audio(\"user_1\", audio_path))","metadata":{"execution":{"iopub.status.busy":"2024-11-11T05:31:38.484907Z","iopub.execute_input":"2024-11-11T05:31:38.485399Z","iopub.status.idle":"2024-11-11T05:31:45.853605Z","shell.execute_reply.started":"2024-11-11T05:31:38.485357Z","shell.execute_reply":"2024-11-11T05:31:45.852478Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(fp, map_location=device)\n/opt/conda/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n","output_type":"stream"},{"name":"stdout","text":"Transcribed Question:  Do I have a meeting tomorrow?\nYes, you have a **Team Standup Meeting** scheduled for tomorrow, **2024-11-10 at 11:00**.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}